# KrunchWrapper Scripts Documentation

This document provides an overview of the scripts in the `scripts` directory of the KrunchWrapper project.

## Dictionary Management Scripts

### `build_python_dict.py`
Creates a Python compression dictionary by assigning unique Unicode symbols to Python keywords, built-in functions, common exceptions, standard library modules, common patterns, and methods. The dictionary is saved in TOML format.

### `build_comprehensive_dicts.py`
Builds comprehensive compression dictionaries for multiple programming languages (Python, JavaScript, Go, Rust). Combines language keywords, built-ins, common libraries/frameworks, and assigns Unicode symbols to them.

### `build_enhanced_dicts.py`
Creates enhanced compression dictionaries with a massive symbol pool and common word support. Uses automatically discovered Unicode symbols, programming language tokens, and common English words, with intelligent prioritization based on frequency and length.

### `check_dict_conflicts.py`
Validates that no two long tokens resolve to the same short macro across dictionary files. Checks for duplicate short tokens, zero-gain mappings, and cross-file conflicts.

### `clean_dictionary.py`
Cleans the Python dictionary by removing Unicode artifacts and specialized tokens that might cause issues. Filters out tokens with Unicode symbols, non-ASCII characters, very short tokens, and hex/binary data.

## Compression Analysis Scripts

### `analyze_single_file.py`
Analyzes a single Python file for compression opportunities. Extracts tokens, calculates potential savings, and identifies the most promising compression opportunities.

### `analyze_large_python_codebase.py`
Performs comprehensive analysis of large Python codebases to find compression opportunities. Searches for Python files, analyzes them for common patterns, and identifies the best tokens for compression.

### `analyze_compressed_opportunities.py`
Analyzes already compressed files to find additional compression opportunities. Identifies frequently occurring patterns in compressed text and suggests new tokens that could be added to dictionaries.

### `analyze_codebase_tokens.py`
Analyzes real codebases to discover frequently used tokens for compression. Scans code files to find common identifiers, string literals, comment patterns, and repeated code patterns.

### `debug_compression.py`
Debugging tool for the compression process. Tests compression on a sample file and provides detailed information about what's happening during compression.

## Dictionary Enhancement Scripts

### `add_opportunities_to_dict.py`
Automatically adds compression opportunities to the Python dictionary. Loads opportunities from analysis results and adds the best ones to the dictionary.

### `add_single_file_opportunities.py`
Adds compression opportunities from single file analysis to the dictionary. Loads tokens from a words.txt file and adds them to the dictionary.

### `auto_expand_dictionaries.py`
Automatically expands compression dictionaries with valuable tokens. Runs codebase analysis to find frequently used tokens and adds the most valuable ones to dictionaries.

### `discover_unicode_symbols.py`
Discovers Unicode symbols that LLMs can understand and use for compression. Systematically scans Unicode blocks to find suitable symbols that are single characters, printable, visible, and don't conflict with common programming syntax.

### `extract_from_devdocs.py`
Extracts common programming tokens from DevDocs documentation. Parses DevDocs JSON files to find frequently mentioned APIs, methods, classes, and patterns across languages.

## Generated Files

### `generated_symbols.py`
Contains a large collection of automatically discovered Unicode symbols for compression. Generated by the `discover_unicode_symbols.py` script.

### `__init__.py`
Empty initialization file that makes the scripts directory a proper Python package. 